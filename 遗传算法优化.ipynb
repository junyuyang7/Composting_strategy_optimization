{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "from deap import base, creator, tools\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找最优模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小值的键: {'CatRegression(k)'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# 文件路径\n",
    "file_paths = [\n",
    "    \"output/TN_NH3_N2O/result_mse_N2O-N loss (%).json\",\n",
    "    \"output/TN_NH3_N2O/result_mse_NH3-N loss (%).json\",\n",
    "    \"output/TN_NH3_N2O/result_mse_TN loss (%).json\"\n",
    "]\n",
    "\n",
    "min_key_set = set()\n",
    "min_value = float('inf')  # 初始值为正无穷大\n",
    "\n",
    "# 遍历每个文件\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "        # 查找最小值的键\n",
    "        for key, value in data.items():\n",
    "            if value < min_value:\n",
    "                min_key_set = {key}\n",
    "                min_value = value\n",
    "            elif value == min_value:\n",
    "                min_key_set.add(key)\n",
    "\n",
    "# 打印最小值的键\n",
    "print(\"最小值的键:\", min_key_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载相应的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_N2O-N loss (%)_ctb_model': <catboost.core.CatBoostRegressor object at 0x000001E7CE724410>, 'model_NH3-N loss (%)_ctb_model': <catboost.core.CatBoostRegressor object at 0x000001E7CE9F6450>, 'model_TN loss (%)_ctb_model': <catboost.core.CatBoostRegressor object at 0x000001E7CE4CE210>}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# 模型文件路径\n",
    "model_files = [\n",
    "    \"output\\TN_NH3_N2O\\model_N2O-N loss (%)\\ctb_model.pkl\",\n",
    "    \"output\\TN_NH3_N2O\\model_NH3-N loss (%)\\ctb_model.pkl\",\n",
    "    \"output\\TN_NH3_N2O\\model_TN loss (%)\\ctb_model.pkl\"\n",
    "]\n",
    "\n",
    "loaded_models = {}  # 用于存储加载的模型\n",
    "\n",
    "# 遍历每个模型文件\n",
    "for model_file in model_files:\n",
    "    # 获取模型名称\n",
    "    model_name = os.path.basename(os.path.dirname(model_file)) + \"_\" + os.path.splitext(os.path.basename(model_file))[0]\n",
    "    \n",
    "    # 加载模型\n",
    "    with open(model_file, 'rb') as file:\n",
    "        loaded_model = pickle.load(file)\n",
    "    \n",
    "    # 将加载的模型存储在字典中，以模型名称作为键\n",
    "    loaded_models[model_name] = loaded_model\n",
    "print(loaded_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取每个模型的输入和输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型名称: data_for_N2O-N loss (%)\n",
      "输入特征: ['material_0', 'initial CN(%)', 'initial moisture content(%)', 'initial pH', 'material_1', 'Excipients', 'initial TN(%)', 'initial TC(%)', 'Additive Species']\n",
      "输出特征: N2O-N loss (%)\n",
      "模型名称: data_for_NH3-N loss (%)\n",
      "输入特征: ['material_0', 'initial CN(%)', 'initial moisture content(%)', 'initial pH', 'material_1', 'Excipients', 'initial TN(%)', 'initial TC(%)', 'Additive Species']\n",
      "输出特征: NH3-N loss (%)\n",
      "模型名称: data_for_TN loss (%)\n",
      "输入特征: ['material_0', 'initial CN(%)', 'initial moisture content(%)', 'initial pH', 'material_1', 'Excipients', 'initial TN(%)', 'initial TC(%)', 'Additive Species']\n",
      "输出特征: TN loss (%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# CSV 文件路径\n",
    "csv_files = [\n",
    "    \"data/TN_NH3_N2O/data_for_N2O-N loss (%).csv\",\n",
    "    \"data/TN_NH3_N2O/data_for_NH3-N loss (%).csv\",\n",
    "    \"data/TN_NH3_N2O/data_for_TN loss (%).csv\"\n",
    "]\n",
    "\n",
    "# 用于存储输入特征和输出特征的列表\n",
    "input_features_list = []\n",
    "output_feature_list = []\n",
    "model_names = []\n",
    "\n",
    "# 遍历每个 CSV 文件\n",
    "for csv_file in csv_files:\n",
    "    # 从文件路径中提取模型名称\n",
    "    model_name = os.path.splitext(os.path.basename(csv_file))[0]\n",
    "    model_names.append(model_name)\n",
    "    \n",
    "    # 读取 CSV 文件\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # 获取输入特征（除了最后一列）和输出特征（最后一列）的列名，并添加到列表中\n",
    "    input_features = list(df.columns[:-1])\n",
    "    output_feature = df.columns[-1]\n",
    "    input_features_list.append(input_features)\n",
    "    output_feature_list.append(output_feature)\n",
    "\n",
    "# 打印模型名称、输入特征和输出特征的列表\n",
    "for model_name, input_features, output_feature in zip(model_names, input_features_list, output_feature_list):\n",
    "    print(\"模型名称:\", model_name)\n",
    "    print(\"输入特征:\", input_features)\n",
    "    print(\"输出特征:\", output_feature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找输入输出的取值范围"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "material_0: Minimum=0, Maximum=6\n",
      "initial CN(%): Minimum=-1.0, Maximum=53.73\n",
      "initial moisture content(%): Minimum=-1.0, Maximum=89.8\n",
      "initial pH: Minimum=-1.0, Maximum=10.7\n",
      "material_1: Minimum=0, Maximum=5\n",
      "Excipients: Minimum=0, Maximum=78\n",
      "initial TN(%): Minimum=-1.0, Maximum=14.56\n",
      "initial TC(%): Minimum=-1.0, Maximum=197.0\n",
      "Additive Species: Minimum=0, Maximum=4\n",
      "N2O-N loss (%): Minimum=-0.0, Maximum=13.05\n",
      "NH3-N loss (%): Minimum=0.0, Maximum=84.51\n",
      "TN loss (%): Minimum=0.2, Maximum=90.5\n",
      "{'material_0': {'Minimum': 0, 'Maximum': 6}, 'initial CN(%)': {'Minimum': -1.0, 'Maximum': 53.73}, 'initial moisture content(%)': {'Minimum': -1.0, 'Maximum': 89.8}, 'initial pH': {'Minimum': -1.0, 'Maximum': 10.7}, 'material_1': {'Minimum': 0, 'Maximum': 5}, 'Excipients': {'Minimum': 0, 'Maximum': 78}, 'initial TN(%)': {'Minimum': -1.0, 'Maximum': 14.56}, 'initial TC(%)': {'Minimum': -1.0, 'Maximum': 197.0}, 'Additive Species': {'Minimum': 0, 'Maximum': 4}, 'N2O-N loss (%)': {'Minimum': -0.0, 'Maximum': 13.05}, 'NH3-N loss (%)': {'Minimum': 0.0, 'Maximum': 84.51}, 'TN loss (%)': {'Minimum': 0.2, 'Maximum': 90.5}}\n"
     ]
    }
   ],
   "source": [
    "# 存储所有输入特征和标签的最小值和最大值的字典\n",
    "min_max_values = {}\n",
    "\n",
    "# 遍历每个 CSV 文件\n",
    "for csv_file in csv_files:\n",
    "    # 读取 CSV 文件\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # 获取输入特征的列名（去除最后一列）\n",
    "    input_features = list(df.columns[:-1])\n",
    "    # 获取标签的列名\n",
    "    label_column = df.columns[-1]\n",
    "    \n",
    "    # 遍历每个输入特征\n",
    "    for feature in input_features:\n",
    "        # 如果特征不存在，创建新的特征项\n",
    "        if feature not in min_max_values:\n",
    "            min_max_values[feature] = {'Minimum': None, 'Maximum': None}\n",
    "        # 计算输入特征的最小值和最大值，并更新字典中的值\n",
    "        if min_max_values[feature]['Minimum'] is None:\n",
    "            min_max_values[feature]['Minimum'] = round(df[feature].min(), 2)\n",
    "        else:\n",
    "            min_max_values[feature]['Minimum'] = min(round(min_max_values[feature]['Minimum'], 2), round(df[feature].min(), 2))\n",
    "        if min_max_values[feature]['Maximum'] is None:\n",
    "            min_max_values[feature]['Maximum'] = round(df[feature].max(), 2)\n",
    "        else:\n",
    "            min_max_values[feature]['Maximum'] = max(round(min_max_values[feature]['Maximum'], 2), round(df[feature].max(), 2))\n",
    "    \n",
    "    # 如果标签不存在，创建新的标签项\n",
    "    if label_column not in min_max_values:\n",
    "        min_max_values[label_column] = {'Minimum': None, 'Maximum': None}\n",
    "    # 计算标签的最小值和最大值，并更新字典中的值\n",
    "    if min_max_values[label_column]['Minimum'] is None:\n",
    "        min_max_values[label_column]['Minimum'] = round(df[label_column].min(), 2)\n",
    "    else:\n",
    "        min_max_values[label_column]['Minimum'] = min(round(min_max_values[label_column]['Minimum'], 2), round(df[label_column].min(), 2))\n",
    "    if min_max_values[label_column]['Maximum'] is None:\n",
    "        min_max_values[label_column]['Maximum'] = round(df[label_column].max(), 2)\n",
    "    else:\n",
    "        min_max_values[label_column]['Maximum'] = max(round(min_max_values[label_column]['Maximum'], 2), round(df[label_column].max(), 2))\n",
    "\n",
    "# 打印每个输入特征和标签的最小值和最大值\n",
    "for category, stats in min_max_values.items():\n",
    "    print(f\"{category}: Minimum={stats['Minimum']}, Maximum={stats['Maximum']}\")\n",
    "\n",
    "print(min_max_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遗传算法优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_N2O-N loss (%)_ctb_model优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Ranges:\n",
      "{'material_0': {'Minimum': 0, 'Maximum': 6}, 'initial CN(%)': {'Minimum': -1.0, 'Maximum': 53.73}, 'initial moisture content(%)': {'Minimum': -1.0, 'Maximum': 89.8}, 'initial pH': {'Minimum': -1.0, 'Maximum': 10.7}, 'material_1': {'Minimum': 0, 'Maximum': 5}, 'Excipients': {'Minimum': 0, 'Maximum': 78}, 'initial TN(%)': {'Minimum': -1.0, 'Maximum': 14.56}, 'initial TC(%)': {'Minimum': -1.0, 'Maximum': 197.0}, 'Additive Species': {'Minimum': 0, 'Maximum': 4}}\n",
      "\n",
      "Output Ranges:\n",
      "{'N2O-N loss (%)': {'Minimum': -0.0, 'Maximum': 13.05}, 'NH3-N loss (%)': {'Minimum': 0.0, 'Maximum': 84.51}, 'TN loss (%)': {'Minimum': 0.2, 'Maximum': 90.5}}\n",
      "Run 1: Best individual with fitness [-3.56353551]\n",
      "Run 2: Best individual with fitness [-3.57894898]\n",
      "Run 3: Best individual with fitness [-6.70563973]\n",
      "Run 4: Best individual with fitness [-2.89247683]\n",
      "Run 5: Best individual with fitness [-4.28506548]\n",
      "Run 6: Best individual with fitness [-3.41823386]\n",
      "Run 7: Best individual with fitness [-2.58425399]\n",
      "Run 8: Best individual with fitness [-4.06125768]\n",
      "Run 9: Best individual with fitness [-2.05111453]\n",
      "Run 10: Best individual with fitness [-2.64250594]\n",
      "Run 11: Best individual with fitness [-1.99146752]\n",
      "Run 12: Best individual with fitness [-2.56456114]\n",
      "Run 13: Best individual with fitness [-7.72250698]\n",
      "Run 14: Best individual with fitness [-3.3173971]\n",
      "Run 15: Best individual with fitness [-3.85450229]\n",
      "Run 16: Best individual with fitness [-5.2805718]\n",
      "Run 17: Best individual with fitness [-4.39033195]\n",
      "Run 18: Best individual with fitness [-1.92023661]\n",
      "Run 19: Best individual with fitness [-3.82321649]\n",
      "Run 20: Best individual with fitness [-6.80279888]\n",
      "Run 21: Best individual with fitness [-4.63640277]\n",
      "Run 22: Best individual with fitness [-3.07664395]\n",
      "Run 23: Best individual with fitness [-3.2750383]\n",
      "Run 24: Best individual with fitness [-3.48375221]\n",
      "Run 25: Best individual with fitness [-2.91872888]\n",
      "Run 26: Best individual with fitness [-3.25556011]\n",
      "Run 27: Best individual with fitness [-2.06854246]\n",
      "Run 28: Best individual with fitness [-2.98740017]\n",
      "Run 29: Best individual with fitness [-3.54733664]\n",
      "Run 30: Best individual with fitness [-3.58593791]\n",
      "Run 31: Best individual with fitness [-2.52876806]\n",
      "Run 32: Best individual with fitness [-4.0201299]\n",
      "Run 33: Best individual with fitness [-3.19039083]\n",
      "Run 34: Best individual with fitness [-2.95599458]\n",
      "Run 35: Best individual with fitness [-3.49067672]\n",
      "Run 36: Best individual with fitness [-3.71773879]\n",
      "Run 37: Best individual with fitness [-2.01617476]\n",
      "Run 38: Best individual with fitness [-3.8903687]\n",
      "Run 39: Best individual with fitness [-3.88806364]\n",
      "Run 40: Best individual with fitness [-3.48588175]\n",
      "Run 41: Best individual with fitness [-6.37985672]\n",
      "Run 42: Best individual with fitness [-2.8654112]\n",
      "Run 43: Best individual with fitness [-2.27664704]\n",
      "Run 44: Best individual with fitness [-1.72995107]\n",
      "Run 45: Best individual with fitness [-3.10606368]\n",
      "Run 46: Best individual with fitness [-3.81366554]\n",
      "Run 47: Best individual with fitness [-2.95938362]\n",
      "Run 48: Best individual with fitness [-6.2870015]\n",
      "Run 49: Best individual with fitness [-7.32724255]\n",
      "Run 50: Best individual with fitness [-4.61121161]\n",
      "Run 51: Best individual with fitness [-2.18936465]\n",
      "Run 52: Best individual with fitness [-3.88810127]\n",
      "Run 53: Best individual with fitness [-3.43660735]\n",
      "Run 54: Best individual with fitness [-3.17977423]\n",
      "Run 55: Best individual with fitness [-3.56234346]\n",
      "Run 56: Best individual with fitness [-2.73170907]\n",
      "Run 57: Best individual with fitness [-3.23163555]\n",
      "Run 58: Best individual with fitness [-2.7312623]\n",
      "Run 59: Best individual with fitness [-3.07366819]\n",
      "Run 60: Best individual with fitness [-3.39931097]\n",
      "Run 61: Best individual with fitness [-2.10328872]\n",
      "Run 62: Best individual with fitness [-7.1996617]\n",
      "Run 63: Best individual with fitness [-4.51841678]\n",
      "Run 64: Best individual with fitness [-4.79895848]\n",
      "Run 65: Best individual with fitness [-2.23282268]\n",
      "Run 66: Best individual with fitness [-2.8950193]\n",
      "Run 67: Best individual with fitness [-2.61226568]\n",
      "Run 68: Best individual with fitness [-4.98667582]\n",
      "Run 69: Best individual with fitness [-2.51124376]\n",
      "Run 70: Best individual with fitness [-3.32459496]\n",
      "Run 71: Best individual with fitness [-2.99179118]\n",
      "Run 72: Best individual with fitness [-3.32615236]\n",
      "Run 73: Best individual with fitness [-4.0041821]\n",
      "Run 74: Best individual with fitness [-5.62165592]\n",
      "Run 75: Best individual with fitness [-2.48563193]\n",
      "Run 76: Best individual with fitness [-5.92840008]\n",
      "Run 77: Best individual with fitness [-3.20978637]\n",
      "Run 78: Best individual with fitness [-4.04641702]\n",
      "Run 79: Best individual with fitness [-3.25403187]\n",
      "Run 80: Best individual with fitness [-6.40056507]\n",
      "Run 81: Best individual with fitness [-2.98762309]\n",
      "Run 82: Best individual with fitness [-2.98949978]\n",
      "Run 83: Best individual with fitness [-2.58875849]\n",
      "Run 84: Best individual with fitness [-6.06762287]\n",
      "Run 85: Best individual with fitness [-6.63419443]\n",
      "Run 86: Best individual with fitness [-2.34830141]\n",
      "Run 87: Best individual with fitness [-2.52768559]\n",
      "Run 88: Best individual with fitness [-2.7505714]\n",
      "Run 89: Best individual with fitness [-3.2307387]\n",
      "Run 90: Best individual with fitness [-2.68296064]\n",
      "Run 91: Best individual with fitness [-2.25062571]\n",
      "Run 92: Best individual with fitness [-6.72886237]\n",
      "Run 93: Best individual with fitness [-2.51823337]\n",
      "Run 94: Best individual with fitness [-3.03918748]\n",
      "Run 95: Best individual with fitness [-3.24754549]\n",
      "Run 96: Best individual with fitness [-2.73171614]\n",
      "Run 97: Best individual with fitness [-2.34685636]\n",
      "Run 98: Best individual with fitness [-3.31706742]\n",
      "Run 99: Best individual with fitness [-3.49152952]\n",
      "Run 100: Best individual with fitness [-3.29207303]\n",
      "Best individuals saved to_N2O-N loss (%): best_individuals.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "\n",
    "# 加载模型\n",
    "model_name_1 = 'model_N2O-N loss (%)_ctb_model'\n",
    "# 假设loaded_models已经定义，用于存储加载的模型\n",
    "# loaded_models = load_models() # 这里是你加载模型的代码，假设已经定义了\n",
    "loaded_model_1 = loaded_models[model_name_1]\n",
    "\n",
    "# 创建输入范围字典和输出范围字典\n",
    "input_ranges_1 = {key: value for key, value in min_max_values.items() if key not in ['N2O-N loss (%)', 'NH3-N loss (%)', 'TN loss (%)']}\n",
    "output_range_1 = {key: value for key, value in min_max_values.items() if key in ['N2O-N loss (%)', 'NH3-N loss (%)', 'TN loss (%)']}\n",
    "\n",
    "print(\"Input Ranges:\")\n",
    "print(input_ranges_1)\n",
    "print(\"\\nOutput Ranges:\")\n",
    "print(output_range_1)\n",
    "\n",
    "# 创建属性名称到数值的映射\n",
    "attribute_mapping = {key: idx for idx, key in enumerate(input_ranges_1.keys())}\n",
    "\n",
    "# 最小化目标函数\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# 定义生成整数属性的方法\n",
    "toolbox.register(\"attr_int\", lambda minimum, maximum: random.randint(round(minimum), round(maximum)))\n",
    "\n",
    "# 定义生成浮点数属性的方法\n",
    "toolbox.register(\"attr_float\", lambda minimum, maximum: random.uniform(minimum, maximum))\n",
    "\n",
    "# 创建个体时根据属性类型选择不同的生成方法\n",
    "def create_individual():\n",
    "    individual = []\n",
    "    for attr_name, attr_info in input_ranges_1.items():\n",
    "        if attr_name in ['material_0', 'material_1', 'Excipients', 'Additive Species']:\n",
    "            individual.append(toolbox.attr_int(attr_info['Minimum'], attr_info['Maximum']))\n",
    "        else:\n",
    "            individual.append(toolbox.attr_float(attr_info['Minimum'], attr_info['Maximum']))\n",
    "    return creator.Individual(individual)\n",
    "\n",
    "# 注册个体生成方法\n",
    "toolbox.register(\"individual\", create_individual)\n",
    "\n",
    "# 初始化种群\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "def evaluate(individual):\n",
    "    # 使用模型进行预测\n",
    "    individual_with_names = {attr_name: value for attr_name, value in zip(input_ranges_1.keys(), individual)}\n",
    "\n",
    "    # 检查每个特征值是否超出范围，如果超出范围则返回一个非常大的适应度值\n",
    "    for key, value in individual_with_names.items():\n",
    "        if key in ['material_0', 'material_1', 'Excipients', 'Additive Species']:\n",
    "            if not isinstance(value, int) or value < input_ranges_1[key]['Minimum'] or value > input_ranges_1[key]['Maximum']:\n",
    "                return (1e6,)  # 返回一个非常大的适应度值，表示不合法的个体\n",
    "        else:\n",
    "            if value < input_ranges_1[key]['Minimum'] or value > input_ranges_1[key]['Maximum']:\n",
    "                return (1e6,)  # 返回一个非常大的适应度值，表示不合法的个体\n",
    "\n",
    "    # 使用模型进行预测\n",
    "    prediction = loaded_model_1.predict([individual])\n",
    "\n",
    "    # 计算模型输出并返回其负值作为适应度（因为我们是最小化问题）\n",
    "    fitness = -prediction\n",
    "    return fitness,\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)  # 交叉方式使用 Blend 交叉\n",
    "# toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.1)  # 变异方式使用高斯变异\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# 进化算法\n",
    "def main(population_size=100, n_generations=50, cxpb=0.5, mutpb=0.2):\n",
    "    pop = toolbox.population(n=population_size)\n",
    "    hof = tools.HallOfFame(1)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", min)\n",
    "\n",
    "    algorithms.eaSimple(pop, toolbox, cxpb=cxpb, mutpb=mutpb, ngen=n_generations, stats=stats, halloffame=hof, verbose=False)\n",
    "\n",
    "    return pop, stats, hof\n",
    "\n",
    "# 调整参数\n",
    "population_size = 200\n",
    "n_generations = 100\n",
    "cxpb = 0.5  # 交叉概率\n",
    "mutpb = 0.01  # 变异概率\n",
    "\n",
    "num_runs = 100  # 运行次数\n",
    "best_individuals = []\n",
    "\n",
    "for i in range(num_runs):\n",
    "    pop, stats, hof = main(population_size, n_generations, cxpb, mutpb)\n",
    "    best_individual = tools.selBest(pop, 1)[0]\n",
    "    print(f\"Run {i+1}: Best individual with fitness {best_individual.fitness.values[0]}\")\n",
    "    best_individual_with_names = {list(input_ranges_1.keys())[idx]: value for idx, value in enumerate(best_individual)}\n",
    "    best_individuals.append((best_individual, best_individual_with_names))\n",
    "\n",
    "# 保存最优个体到CSV文件\n",
    "file_name = \"best_individuals_N2O-N loss (%).csv\"\n",
    "data = []\n",
    "columns = list(input_ranges_1.keys()) + [\"N2O-N loss (%)\"]\n",
    "for best_individual, best_individual_with_names in best_individuals:\n",
    "    row = [best_individual_with_names[attr] for attr in input_ranges_1.keys()]\n",
    "    row.append(-best_individual.fitness.values[0])  # 添加适应度值\n",
    "    data.append(row)\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv(file_name, index=False)\n",
    "\n",
    "print(\"Best individuals saved to_N2O-N loss (%):\", file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从最优个体找出最小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combinations with minimum N2O-N loss ([1.72995107]%):\n",
      "material_0                                        4\n",
      "initial CN(%)                             45.994759\n",
      "initial moisture content(%)                8.003134\n",
      "initial pH                                -0.903053\n",
      "material_1                                        2\n",
      "Excipients                                       41\n",
      "initial TN(%)                              5.065161\n",
      "initial TC(%)                             33.578267\n",
      "Additive Species                                  0\n",
      "N2O-N loss (%)                 [1.7299510694982903]\n",
      "Name: 43, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 从保存的文件中找到标题为\"N2O-N loss (%)\"的最小值对应的组合\n",
    "min_N2O_loss_combinations = []\n",
    "min_N2O_loss = min(df['N2O-N loss (%)'])\n",
    "for index, row in df.iterrows():\n",
    "    if row['N2O-N loss (%)'] == min_N2O_loss:\n",
    "        min_N2O_loss_combinations.append(row)\n",
    "\n",
    "print(f\"\\nCombinations with minimum N2O-N loss ({min_N2O_loss}%):\")\n",
    "for combination in min_N2O_loss_combinations:\n",
    "    print(combination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_NH3-N loss (%)_ctb_model优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Ranges:\n",
      "{'material_0': {'Minimum': 0, 'Maximum': 6}, 'initial CN(%)': {'Minimum': -1.0, 'Maximum': 53.73}, 'initial moisture content(%)': {'Minimum': -1.0, 'Maximum': 89.8}, 'initial pH': {'Minimum': -1.0, 'Maximum': 10.7}, 'material_1': {'Minimum': 0, 'Maximum': 5}, 'Excipients': {'Minimum': 0, 'Maximum': 78}, 'initial TN(%)': {'Minimum': -1.0, 'Maximum': 14.56}, 'initial TC(%)': {'Minimum': -1.0, 'Maximum': 197.0}, 'Additive Species': {'Minimum': 0, 'Maximum': 4}}\n",
      "\n",
      "Output Ranges:\n",
      "{'NH3-N loss (%)': {'Minimum': 0.0, 'Maximum': 84.51}, 'TN loss (%)': {'Minimum': 0.2, 'Maximum': 90.5}}\n",
      "Run 1: Best individual with fitness [-19.99296867]\n",
      "Run 2: Best individual with fitness [-21.26771572]\n",
      "Run 3: Best individual with fitness [-23.0845398]\n",
      "Run 4: Best individual with fitness [-19.5720922]\n",
      "Run 5: Best individual with fitness [-21.73998721]\n",
      "Run 6: Best individual with fitness [-21.4707412]\n",
      "Run 7: Best individual with fitness [-24.56127793]\n",
      "Run 8: Best individual with fitness [-20.63281386]\n",
      "Run 9: Best individual with fitness [-17.80217724]\n",
      "Run 10: Best individual with fitness [-16.18912344]\n",
      "Run 11: Best individual with fitness [-18.62101058]\n",
      "Run 12: Best individual with fitness [-17.6144551]\n",
      "Run 13: Best individual with fitness [-18.12984574]\n",
      "Run 14: Best individual with fitness [-22.56179024]\n",
      "Run 15: Best individual with fitness [-20.43645637]\n",
      "Run 16: Best individual with fitness [-19.08559611]\n",
      "Run 17: Best individual with fitness [-17.96508636]\n",
      "Run 18: Best individual with fitness [-22.09225313]\n",
      "Run 19: Best individual with fitness [-23.65488018]\n",
      "Run 20: Best individual with fitness [-17.25653472]\n",
      "Run 21: Best individual with fitness [-20.21103789]\n",
      "Run 22: Best individual with fitness [-25.50367467]\n",
      "Run 23: Best individual with fitness [-21.82503478]\n",
      "Run 24: Best individual with fitness [-20.10138647]\n",
      "Run 25: Best individual with fitness [-26.74951067]\n",
      "Run 26: Best individual with fitness [-21.29825634]\n",
      "Run 27: Best individual with fitness [-16.02930523]\n",
      "Run 28: Best individual with fitness [-23.91361281]\n",
      "Run 29: Best individual with fitness [-28.22833353]\n",
      "Run 30: Best individual with fitness [-18.98959564]\n",
      "Run 31: Best individual with fitness [-18.343236]\n",
      "Run 32: Best individual with fitness [-17.53780652]\n",
      "Run 33: Best individual with fitness [-27.34231591]\n",
      "Run 34: Best individual with fitness [-17.63248795]\n",
      "Run 35: Best individual with fitness [-18.91918783]\n",
      "Run 36: Best individual with fitness [-21.68464127]\n",
      "Run 37: Best individual with fitness [-19.99673476]\n",
      "Run 38: Best individual with fitness [-18.85971253]\n",
      "Run 39: Best individual with fitness [-18.6834462]\n",
      "Run 40: Best individual with fitness [-20.14077138]\n",
      "Run 41: Best individual with fitness [-18.00168971]\n",
      "Run 42: Best individual with fitness [-18.05148024]\n",
      "Run 43: Best individual with fitness [-17.67575892]\n",
      "Run 44: Best individual with fitness [-17.42049141]\n",
      "Run 45: Best individual with fitness [-21.362671]\n",
      "Run 46: Best individual with fitness [-19.3806214]\n",
      "Run 47: Best individual with fitness [-23.13817659]\n",
      "Run 48: Best individual with fitness [-18.7862856]\n",
      "Run 49: Best individual with fitness [-20.17205674]\n",
      "Run 50: Best individual with fitness [-21.03358645]\n",
      "Run 51: Best individual with fitness [-17.83167236]\n",
      "Run 52: Best individual with fitness [-24.51952968]\n",
      "Run 53: Best individual with fitness [-23.9726313]\n",
      "Run 54: Best individual with fitness [-20.24467673]\n",
      "Run 55: Best individual with fitness [-19.99331817]\n",
      "Run 56: Best individual with fitness [-15.77313954]\n",
      "Run 57: Best individual with fitness [-19.4029992]\n",
      "Run 58: Best individual with fitness [-20.18894951]\n",
      "Run 59: Best individual with fitness [-21.07694203]\n",
      "Run 60: Best individual with fitness [-17.86726501]\n",
      "Run 61: Best individual with fitness [-21.65907146]\n",
      "Run 62: Best individual with fitness [-18.56855109]\n",
      "Run 63: Best individual with fitness [-19.97115259]\n",
      "Run 64: Best individual with fitness [-27.97791894]\n",
      "Run 65: Best individual with fitness [-20.89040947]\n",
      "Run 66: Best individual with fitness [-25.14826027]\n",
      "Run 67: Best individual with fitness [-22.25624091]\n",
      "Run 68: Best individual with fitness [-16.2846316]\n",
      "Run 69: Best individual with fitness [-18.05565344]\n",
      "Run 70: Best individual with fitness [-18.18370711]\n",
      "Run 71: Best individual with fitness [-22.89178759]\n",
      "Run 72: Best individual with fitness [-17.87467332]\n",
      "Run 73: Best individual with fitness [-17.23865377]\n",
      "Run 74: Best individual with fitness [-20.65292839]\n",
      "Run 75: Best individual with fitness [-22.76819406]\n",
      "Run 76: Best individual with fitness [-24.99281948]\n",
      "Run 77: Best individual with fitness [-26.87473472]\n",
      "Run 78: Best individual with fitness [-24.93513818]\n",
      "Run 79: Best individual with fitness [-30.30128104]\n",
      "Run 80: Best individual with fitness [-22.97982551]\n",
      "Run 81: Best individual with fitness [-16.80902669]\n",
      "Run 82: Best individual with fitness [-24.19850297]\n",
      "Run 83: Best individual with fitness [-19.32972919]\n",
      "Run 84: Best individual with fitness [-20.53420825]\n",
      "Run 85: Best individual with fitness [-18.60986132]\n",
      "Run 86: Best individual with fitness [-33.97744797]\n",
      "Run 87: Best individual with fitness [-18.87823147]\n",
      "Run 88: Best individual with fitness [-19.58608894]\n",
      "Run 89: Best individual with fitness [-23.47466061]\n",
      "Run 90: Best individual with fitness [-20.56227395]\n",
      "Run 91: Best individual with fitness [-20.33927804]\n",
      "Run 92: Best individual with fitness [-20.71468467]\n",
      "Run 93: Best individual with fitness [-22.18078712]\n",
      "Run 94: Best individual with fitness [-15.85772296]\n",
      "Run 95: Best individual with fitness [-26.69144261]\n",
      "Run 96: Best individual with fitness [-20.09257482]\n",
      "Run 97: Best individual with fitness [-23.11407328]\n",
      "Run 98: Best individual with fitness [-19.61681172]\n",
      "Run 99: Best individual with fitness [-22.27512033]\n",
      "Run 100: Best individual with fitness [-19.73450953]\n",
      "Best individuals saved to_NH3-N loss (%): best_individuals_NH3-N loss (%).csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "\n",
    "# 加载模型\n",
    "model_name_1 = 'model_NH3-N loss (%)_ctb_model'\n",
    "# 假设loaded_models已经定义，用于存储加载的模型\n",
    "# loaded_models = load_models() # 这里是你加载模型的代码，假设已经定义了\n",
    "loaded_model_1 = loaded_models[model_name_1]\n",
    "\n",
    "# 创建输入范围字典和输出范围字典\n",
    "input_ranges_1 = {key: value for key, value in min_max_values.items() if key not in ['N2O-N loss (%)', 'NH3-N loss (%)', 'TN loss (%)']}\n",
    "output_range_1 = {key: value for key, value in min_max_values.items() if key in ['NH3-N loss (%)', 'TN loss (%)']}\n",
    "\n",
    "print(\"Input Ranges:\")\n",
    "print(input_ranges_1)\n",
    "print(\"\\nOutput Ranges:\")\n",
    "print(output_range_1)\n",
    "\n",
    "# 创建属性名称到数值的映射\n",
    "attribute_mapping = {key: idx for idx, key in enumerate(input_ranges_1.keys())}\n",
    "\n",
    "# 最小化目标函数\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# 定义生成整数属性的方法\n",
    "toolbox.register(\"attr_int\", lambda minimum, maximum: random.randint(round(minimum), round(maximum)))\n",
    "\n",
    "# 定义生成浮点数属性的方法\n",
    "toolbox.register(\"attr_float\", lambda minimum, maximum: random.uniform(minimum, maximum))\n",
    "\n",
    "# 创建个体时根据属性类型选择不同的生成方法\n",
    "def create_individual():\n",
    "    individual = []\n",
    "    for attr_name, attr_info in input_ranges_1.items():\n",
    "        if attr_name in ['material_0', 'material_1', 'Excipients', 'Additive Species']:\n",
    "            individual.append(toolbox.attr_int(attr_info['Minimum'], attr_info['Maximum']))\n",
    "        else:\n",
    "            individual.append(toolbox.attr_float(attr_info['Minimum'], attr_info['Maximum']))\n",
    "    return creator.Individual(individual)\n",
    "\n",
    "# 注册个体生成方法\n",
    "toolbox.register(\"individual\", create_individual)\n",
    "\n",
    "# 初始化种群\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "def evaluate(individual):\n",
    "    # 使用模型进行预测\n",
    "    individual_with_names = {attr_name: value for attr_name, value in zip(input_ranges_1.keys(), individual)}\n",
    "\n",
    "    # 检查每个特征值是否超出范围，如果超出范围则返回一个非常大的适应度值\n",
    "    for key, value in individual_with_names.items():\n",
    "        if key in ['material_0', 'material_1', 'Excipients', 'Additive Species']:\n",
    "            if not isinstance(value, int) or value < input_ranges_1[key]['Minimum'] or value > input_ranges_1[key]['Maximum']:\n",
    "                return (1e6,)  # 返回一个非常大的适应度值，表示不合法的个体\n",
    "        else:\n",
    "            if value < input_ranges_1[key]['Minimum'] or value > input_ranges_1[key]['Maximum']:\n",
    "                return (1e6,)  # 返回一个非常大的适应度值，表示不合法的个体\n",
    "\n",
    "    # 使用模型进行预测\n",
    "    prediction = loaded_model_1.predict([individual])\n",
    "\n",
    "    # 计算模型输出并返回其负值作为适应度（因为我们是最小化问题）\n",
    "    fitness = -prediction\n",
    "    return fitness,\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)  # 交叉方式使用 Blend 交叉\n",
    "# toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.1)  # 变异方式使用高斯变异\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# 进化算法\n",
    "def main(population_size=100, n_generations=50, cxpb=0.5, mutpb=0.2):\n",
    "    pop = toolbox.population(n=population_size)\n",
    "    hof = tools.HallOfFame(1)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", min)\n",
    "\n",
    "    algorithms.eaSimple(pop, toolbox, cxpb=cxpb, mutpb=mutpb, ngen=n_generations, stats=stats, halloffame=hof, verbose=False)\n",
    "\n",
    "    return pop, stats, hof\n",
    "\n",
    "# 调整参数\n",
    "population_size = 60\n",
    "n_generations = 100\n",
    "cxpb = 0.5  # 交叉概率\n",
    "mutpb = 0.01  # 变异概率\n",
    "\n",
    "num_runs = 100  # 运行次数\n",
    "best_individuals = []\n",
    "\n",
    "for i in range(num_runs):\n",
    "    pop, stats, hof = main(population_size, n_generations, cxpb, mutpb)\n",
    "    best_individual = tools.selBest(pop, 1)[0]\n",
    "    print(f\"Run {i+1}: Best individual with fitness {best_individual.fitness.values[0]}\")\n",
    "    best_individual_with_names = {list(input_ranges_1.keys())[idx]: value for idx, value in enumerate(best_individual)}\n",
    "    best_individuals.append((best_individual, best_individual_with_names))\n",
    "\n",
    "# 保存最优个体到CSV文件\n",
    "file_name = \"best_individuals_NH3-N loss (%).csv\"\n",
    "data = []\n",
    "columns = list(input_ranges_1.keys()) + [\"NH3-N loss (%)\"]\n",
    "for best_individual, best_individual_with_names in best_individuals:\n",
    "    row = [best_individual_with_names[attr] for attr in input_ranges_1.keys()]\n",
    "    row.append(-best_individual.fitness.values[0])  # 添加适应度值\n",
    "    data.append(row)\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv(file_name, index=False)\n",
    "\n",
    "print(\"Best individuals saved to_NH3-N loss (%):\", file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从最优个体找出最小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combinations with minimum N2O-N loss ([15.77313954]%):\n",
      "material_0                                        2\n",
      "initial CN(%)                              13.96201\n",
      "initial moisture content(%)               72.026239\n",
      "initial pH                                  2.11136\n",
      "material_1                                        5\n",
      "Excipients                                       39\n",
      "initial TN(%)                              6.427479\n",
      "initial TC(%)                            131.827844\n",
      "Additive Species                                  1\n",
      "NH3-N loss (%)                 [15.773139544012277]\n",
      "Name: 55, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 从保存的文件中找到标题为\"NH3-N loss (%)\"的最小值对应的组合\n",
    "min_NH3_N_loss_combinations = []\n",
    "min_NH3_N_loss = min(df['NH3-N loss (%)'])\n",
    "for index, row in df.iterrows():\n",
    "    if row['NH3-N loss (%)'] == min_NH3_N_loss:\n",
    "        min_NH3_N_loss_combinations.append(row)\n",
    "\n",
    "print(f\"\\nCombinations with minimum N2O-N loss ({min_NH3_N_loss}%):\")\n",
    "for combination in min_NH3_N_loss_combinations:\n",
    "    print(combination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_TN loss (%)_ctb_model优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Ranges:\n",
      "{'material_0': {'Minimum': 0, 'Maximum': 6}, 'initial CN(%)': {'Minimum': -1.0, 'Maximum': 53.73}, 'initial moisture content(%)': {'Minimum': -1.0, 'Maximum': 89.8}, 'initial pH': {'Minimum': -1.0, 'Maximum': 10.7}, 'material_1': {'Minimum': 0, 'Maximum': 5}, 'Excipients': {'Minimum': 0, 'Maximum': 78}, 'initial TN(%)': {'Minimum': -1.0, 'Maximum': 14.56}, 'initial TC(%)': {'Minimum': -1.0, 'Maximum': 197.0}, 'Additive Species': {'Minimum': 0, 'Maximum': 4}}\n",
      "\n",
      "Output Ranges:\n",
      "{'TN loss (%)': {'Minimum': 0.2, 'Maximum': 90.5}}\n",
      "Run 1: Best individual with fitness [-37.97885911]\n",
      "Run 2: Best individual with fitness [-45.91499866]\n",
      "Run 3: Best individual with fitness [-40.86607202]\n",
      "Run 4: Best individual with fitness [-35.54169814]\n",
      "Run 5: Best individual with fitness [-46.21301536]\n",
      "Run 6: Best individual with fitness [-39.5328515]\n",
      "Run 7: Best individual with fitness [-39.05719107]\n",
      "Run 8: Best individual with fitness [-36.84531856]\n",
      "Run 9: Best individual with fitness [-43.6608655]\n",
      "Run 10: Best individual with fitness [-40.37948621]\n",
      "Run 11: Best individual with fitness [-34.56761079]\n",
      "Run 12: Best individual with fitness [-36.9280195]\n",
      "Run 13: Best individual with fitness [-44.42484145]\n",
      "Run 14: Best individual with fitness [-44.31846606]\n",
      "Run 15: Best individual with fitness [-37.9904211]\n",
      "Run 16: Best individual with fitness [-37.58079414]\n",
      "Run 17: Best individual with fitness [-43.71602918]\n",
      "Run 18: Best individual with fitness [-39.07582521]\n",
      "Run 19: Best individual with fitness [-46.4733819]\n",
      "Run 20: Best individual with fitness [-48.31520712]\n",
      "Run 21: Best individual with fitness [-43.56277411]\n",
      "Run 22: Best individual with fitness [-37.86737358]\n",
      "Run 23: Best individual with fitness [-38.04957204]\n",
      "Run 24: Best individual with fitness [-41.09243249]\n",
      "Run 25: Best individual with fitness [-43.73457695]\n",
      "Run 26: Best individual with fitness [-43.57313606]\n",
      "Run 27: Best individual with fitness [-42.67619672]\n",
      "Run 28: Best individual with fitness [-35.21131503]\n",
      "Run 29: Best individual with fitness [-37.16736083]\n",
      "Run 30: Best individual with fitness [-45.36319806]\n",
      "Run 31: Best individual with fitness [-41.50613142]\n",
      "Run 32: Best individual with fitness [-39.73491948]\n",
      "Run 33: Best individual with fitness [-33.15655421]\n",
      "Run 34: Best individual with fitness [-40.14427157]\n",
      "Run 35: Best individual with fitness [-35.99616884]\n",
      "Run 36: Best individual with fitness [-69.39415503]\n",
      "Run 37: Best individual with fitness [-40.05626319]\n",
      "Run 38: Best individual with fitness [-38.0997779]\n",
      "Run 39: Best individual with fitness [-43.59598727]\n",
      "Run 40: Best individual with fitness [-40.53544699]\n",
      "Run 41: Best individual with fitness [-34.73632286]\n",
      "Run 42: Best individual with fitness [-36.93915873]\n",
      "Run 43: Best individual with fitness [-37.4903396]\n",
      "Run 44: Best individual with fitness [-37.55784044]\n",
      "Run 45: Best individual with fitness [-47.35969172]\n",
      "Run 46: Best individual with fitness [-44.8875008]\n",
      "Run 47: Best individual with fitness [-33.46956511]\n",
      "Run 48: Best individual with fitness [-37.25852496]\n",
      "Run 49: Best individual with fitness [-36.46001943]\n",
      "Run 50: Best individual with fitness [-44.10426564]\n",
      "Run 51: Best individual with fitness [-40.9850401]\n",
      "Run 52: Best individual with fitness [-34.92925292]\n",
      "Run 53: Best individual with fitness [-43.21674511]\n",
      "Run 54: Best individual with fitness [-34.85670212]\n",
      "Run 55: Best individual with fitness [-42.58130828]\n",
      "Run 56: Best individual with fitness [-39.96067747]\n",
      "Run 57: Best individual with fitness [-37.47475588]\n",
      "Run 58: Best individual with fitness [-39.29148276]\n",
      "Run 59: Best individual with fitness [-32.24972531]\n",
      "Run 60: Best individual with fitness [-38.653587]\n",
      "Run 61: Best individual with fitness [-45.61310965]\n",
      "Run 62: Best individual with fitness [-37.41102902]\n",
      "Run 63: Best individual with fitness [-47.21170068]\n",
      "Run 64: Best individual with fitness [-39.10594968]\n",
      "Run 65: Best individual with fitness [-44.41339096]\n",
      "Run 66: Best individual with fitness [-39.86222107]\n",
      "Run 67: Best individual with fitness [-44.66560822]\n",
      "Run 68: Best individual with fitness [-38.95506069]\n",
      "Run 69: Best individual with fitness [-44.93043292]\n",
      "Run 70: Best individual with fitness [-37.76328173]\n",
      "Run 71: Best individual with fitness [-44.02664137]\n",
      "Run 72: Best individual with fitness [-40.28533271]\n",
      "Run 73: Best individual with fitness [-36.99754629]\n",
      "Run 74: Best individual with fitness [-46.09379453]\n",
      "Run 75: Best individual with fitness [-35.5279379]\n",
      "Run 76: Best individual with fitness [-42.73640407]\n",
      "Run 77: Best individual with fitness [-39.08223714]\n",
      "Run 78: Best individual with fitness [-47.34326348]\n",
      "Run 79: Best individual with fitness [-37.7923774]\n",
      "Run 80: Best individual with fitness [-35.76059991]\n",
      "Run 81: Best individual with fitness [-37.34644579]\n",
      "Run 82: Best individual with fitness [-38.84814925]\n",
      "Run 83: Best individual with fitness [-44.17394972]\n",
      "Run 84: Best individual with fitness [-39.56417195]\n",
      "Run 85: Best individual with fitness [-41.18881527]\n",
      "Run 86: Best individual with fitness [-36.03880243]\n",
      "Run 87: Best individual with fitness [-52.44014715]\n",
      "Run 88: Best individual with fitness [-37.12629645]\n",
      "Run 89: Best individual with fitness [-43.53570159]\n",
      "Run 90: Best individual with fitness [-40.56449443]\n",
      "Run 91: Best individual with fitness [-44.89002113]\n",
      "Run 92: Best individual with fitness [-53.15493917]\n",
      "Run 93: Best individual with fitness [-47.0542908]\n",
      "Run 94: Best individual with fitness [-40.03500336]\n",
      "Run 95: Best individual with fitness [-44.13044298]\n",
      "Run 96: Best individual with fitness [-36.67233958]\n",
      "Run 97: Best individual with fitness [-46.78937701]\n",
      "Run 98: Best individual with fitness [-38.31113644]\n",
      "Run 99: Best individual with fitness [-60.69309051]\n",
      "Run 100: Best individual with fitness [-48.36700983]\n",
      "Best individuals saved to_TN loss (%): best_individuals_TN loss (%).csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "\n",
    "# 加载模型\n",
    "model_name_1 = 'model_TN loss (%)_ctb_model'\n",
    "# 假设loaded_models已经定义，用于存储加载的模型\n",
    "# loaded_models = load_models() # 这里是你加载模型的代码，假设已经定义了\n",
    "loaded_model_1 = loaded_models[model_name_1]\n",
    "\n",
    "# 创建输入范围字典和输出范围字典\n",
    "input_ranges_1 = {key: value for key, value in min_max_values.items() if key not in ['N2O-N loss (%)', 'NH3-N loss (%)', 'TN loss (%)']}\n",
    "output_range_1 = {key: value for key, value in min_max_values.items() if key in ['TN loss (%)']}\n",
    "\n",
    "print(\"Input Ranges:\")\n",
    "print(input_ranges_1)\n",
    "print(\"\\nOutput Ranges:\")\n",
    "print(output_range_1)\n",
    "\n",
    "# 创建属性名称到数值的映射\n",
    "attribute_mapping = {key: idx for idx, key in enumerate(input_ranges_1.keys())}\n",
    "\n",
    "# 最小化目标函数\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# 定义生成整数属性的方法\n",
    "toolbox.register(\"attr_int\", lambda minimum, maximum: random.randint(round(minimum), round(maximum)))\n",
    "\n",
    "# 定义生成浮点数属性的方法\n",
    "toolbox.register(\"attr_float\", lambda minimum, maximum: random.uniform(minimum, maximum))\n",
    "\n",
    "# 创建个体时根据属性类型选择不同的生成方法\n",
    "def create_individual():\n",
    "    individual = []\n",
    "    for attr_name, attr_info in input_ranges_1.items():\n",
    "        if attr_name in ['material_0', 'material_1', 'Excipients', 'Additive Species']:\n",
    "            individual.append(toolbox.attr_int(attr_info['Minimum'], attr_info['Maximum']))\n",
    "        else:\n",
    "            individual.append(toolbox.attr_float(attr_info['Minimum'], attr_info['Maximum']))\n",
    "    return creator.Individual(individual)\n",
    "\n",
    "# 注册个体生成方法\n",
    "toolbox.register(\"individual\", create_individual)\n",
    "\n",
    "# 初始化种群\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "def evaluate(individual):\n",
    "    # 使用模型进行预测\n",
    "    individual_with_names = {attr_name: value for attr_name, value in zip(input_ranges_1.keys(), individual)}\n",
    "\n",
    "    # 检查每个特征值是否超出范围，如果超出范围则返回一个非常大的适应度值\n",
    "    for key, value in individual_with_names.items():\n",
    "        if key in ['material_0', 'material_1', 'Excipients', 'Additive Species']:\n",
    "            if not isinstance(value, int) or value < input_ranges_1[key]['Minimum'] or value > input_ranges_1[key]['Maximum']:\n",
    "                return (1e6,)  # 返回一个非常大的适应度值，表示不合法的个体\n",
    "        else:\n",
    "            if value < input_ranges_1[key]['Minimum'] or value > input_ranges_1[key]['Maximum']:\n",
    "                return (1e6,)  # 返回一个非常大的适应度值，表示不合法的个体\n",
    "\n",
    "    # 使用模型进行预测\n",
    "    prediction = loaded_model_1.predict([individual])\n",
    "\n",
    "    # 计算模型输出并返回其负值作为适应度（因为我们是最小化问题）\n",
    "    fitness = -prediction\n",
    "    return fitness,\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)  # 交叉方式使用 Blend 交叉\n",
    "# toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.1)  # 变异方式使用高斯变异\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# 进化算法\n",
    "def main(population_size=100, n_generations=50, cxpb=0.5, mutpb=0.2):\n",
    "    pop = toolbox.population(n=population_size)\n",
    "    hof = tools.HallOfFame(1)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", min)\n",
    "\n",
    "    algorithms.eaSimple(pop, toolbox, cxpb=cxpb, mutpb=mutpb, ngen=n_generations, stats=stats, halloffame=hof, verbose=False)\n",
    "\n",
    "    return pop, stats, hof\n",
    "\n",
    "# 调整参数\n",
    "population_size = 100\n",
    "n_generations = 50\n",
    "cxpb = 0.3  # 交叉概率\n",
    "mutpb = 0.02  # 变异概率\n",
    "\n",
    "num_runs = 100  # 运行次数\n",
    "best_individuals = []\n",
    "\n",
    "for i in range(num_runs):\n",
    "    pop, stats, hof = main(population_size, n_generations, cxpb, mutpb)\n",
    "    best_individual = tools.selBest(pop, 1)[0]\n",
    "    print(f\"Run {i+1}: Best individual with fitness {best_individual.fitness.values[0]}\")\n",
    "    best_individual_with_names = {list(input_ranges_1.keys())[idx]: value for idx, value in enumerate(best_individual)}\n",
    "    best_individuals.append((best_individual, best_individual_with_names))\n",
    "\n",
    "# 保存最优个体到CSV文件\n",
    "file_name = \"best_individuals_TN loss (%).csv\"\n",
    "data = []\n",
    "columns = list(input_ranges_1.keys()) + [\"TN loss (%)\"]\n",
    "for best_individual, best_individual_with_names in best_individuals:\n",
    "    row = [best_individual_with_names[attr] for attr in input_ranges_1.keys()]\n",
    "    row.append(-best_individual.fitness.values[0])  # 添加适应度值\n",
    "    data.append(row)\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv(file_name, index=False)\n",
    "\n",
    "print(\"Best individuals saved to_TN loss (%):\", file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从最优个体找出最小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combinations with minimum N2O-N loss ([32.24972531]%):\n",
      "material_0                                       1\n",
      "initial CN(%)                              4.42864\n",
      "initial moisture content(%)               33.91675\n",
      "initial pH                                9.506107\n",
      "material_1                                       3\n",
      "Excipients                                      52\n",
      "initial TN(%)                            11.699848\n",
      "initial TC(%)                            79.116854\n",
      "Additive Species                                 4\n",
      "TN loss (%)                    [32.24972530675092]\n",
      "Name: 58, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 从保存的文件中找到标题为\"TN loss (%)\"的最小值对应的组合\n",
    "min_TN_loss_combinations = []\n",
    "min_TN_loss = min(df['TN loss (%)'])\n",
    "for index, row in df.iterrows():\n",
    "    if row['TN loss (%)'] == min_TN_loss:\n",
    "        min_TN_loss_combinations.append(row)\n",
    "\n",
    "print(f\"\\nCombinations with minimum N2O-N loss ({min_TN_loss}%):\")\n",
    "for combination in min_TN_loss_combinations:\n",
    "    print(combination)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
